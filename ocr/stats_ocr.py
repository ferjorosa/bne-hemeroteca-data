"""
OCR Statistics Script
====================
This script analyzes JSONL files generated by olmOCR and provides statistics:
- Total number of rows (pages) processed
- Total input tokens and output tokens
- Language distribution (primary_language occurrences)

The script scans all JSONL files in data_ocr/olmocr/results directory.
"""

import os
import json
import glob
from collections import Counter
from pathlib import Path

# Get project root (script is in ocr/, so go up one level)
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)

# Path to results directory
RESULTS_DIR = os.path.join(PROJECT_ROOT, "data_ocr", "olmocr", "results")


def analyze_jsonl_files():
    """Analyze all JSONL files in the results directory."""
    
    # Find all JSONL files
    jsonl_files = glob.glob(os.path.join(RESULTS_DIR, "*.jsonl"))
    
    if not jsonl_files:
        print(f"No JSONL files found in {RESULTS_DIR}")
        return
    
    print(f"Found {len(jsonl_files)} JSONL file(s)")
    print(f"Scanning directory: {RESULTS_DIR}\n")
    
    # Statistics counters
    total_rows = 0
    total_input_tokens = 0
    total_output_tokens = 0
    language_counter = Counter()
    
    # Process each JSONL file
    for jsonl_file in sorted(jsonl_files):
        file_rows = 0
        file_input_tokens = 0
        file_output_tokens = 0
        
        try:
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        data = json.loads(line)
                        total_rows += 1
                        file_rows += 1
                        
                        # Extract token counts from metadata
                        metadata = data.get('metadata', {})
                        input_tokens = metadata.get('total-input-tokens', 0)
                        output_tokens = metadata.get('total-output-tokens', 0)
                        
                        total_input_tokens += input_tokens
                        total_output_tokens += output_tokens
                        file_input_tokens += input_tokens
                        file_output_tokens += output_tokens
                        
                        # Extract primary_language from attributes
                        attributes = data.get('attributes', {})
                        primary_language = attributes.get('primary_language', [])
                        
                        # primary_language is a list, so count each language in the list
                        if isinstance(primary_language, list):
                            for lang in primary_language:
                                if lang:  # Skip empty strings
                                    language_counter[lang] += 1
                        elif primary_language:  # Handle case where it's not a list
                            language_counter[primary_language] += 1
                            
                    except json.JSONDecodeError as e:
                        print(f"Warning: Failed to parse JSON on line {line_num} of {os.path.basename(jsonl_file)}: {e}")
                        continue
        
        except Exception as e:
            print(f"Error processing {os.path.basename(jsonl_file)}: {e}")
            continue
    
    # Print results
    print("=" * 60)
    print("OCR STATISTICS")
    print("=" * 60)
    print(f"\nTotal Rows (Pages): {total_rows:,}")
    print(f"\nToken Statistics:")
    print(f"  Total Input Tokens:  {total_input_tokens:,}")
    print(f"  Total Output Tokens: {total_output_tokens:,}")
    print(f"  Total Tokens:        {total_input_tokens + total_output_tokens:,}")
    
    print(f"\nLanguage Distribution (Primary Language):")
    if language_counter:
        # Sort by count (descending)
        for lang, count in language_counter.most_common():
            percentage = (count / total_rows) * 100 if total_rows > 0 else 0
            print(f"  {lang}: {count:,} occurrences ({percentage:.2f}%)")
    else:
        print("  No language data found")
    
    print("\n" + "=" * 60)


if __name__ == "__main__":
    analyze_jsonl_files()

